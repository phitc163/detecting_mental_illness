{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6841511,"sourceType":"datasetVersion","datasetId":3932931}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-19T04:04:59.312251Z","iopub.execute_input":"2023-12-19T04:04:59.312536Z","iopub.status.idle":"2023-12-19T04:05:12.103242Z","shell.execute_reply.started":"2023-12-19T04:04:59.312510Z","shell.execute_reply":"2023-12-19T04:05:12.102133Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport nltk\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer\nfrom transformers import BertForSequenceClassification\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import AdamW\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import f1_score, roc_curve, auc\nfrom sklearn.preprocessing import StandardScaler\nfrom copy import deepcopy\nfrom transformers import BertTokenizer, BertModel","metadata":{"execution":{"iopub.status.busy":"2023-12-19T04:05:12.105096Z","iopub.execute_input":"2023-12-19T04:05:12.105392Z","iopub.status.idle":"2023-12-19T04:05:25.768856Z","shell.execute_reply.started":"2023-12-19T04:05:12.105366Z","shell.execute_reply":"2023-12-19T04:05:25.767976Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-12-19T04:05:25.769889Z","iopub.execute_input":"2023-12-19T04:05:25.770202Z","iopub.status.idle":"2023-12-19T04:05:25.774463Z","shell.execute_reply.started":"2023-12-19T04:05:25.770173Z","shell.execute_reply":"2023-12-19T04:05:25.773444Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_ = pd.read_csv(\"/kaggle/input/mental-cleaned/final_cleaned_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-19T04:05:25.776672Z","iopub.execute_input":"2023-12-19T04:05:25.777015Z","iopub.status.idle":"2023-12-19T04:05:27.054150Z","shell.execute_reply.started":"2023-12-19T04:05:25.776987Z","shell.execute_reply":"2023-12-19T04:05:27.053348Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T04:05:27.055195Z","iopub.execute_input":"2023-12-19T04:05:27.055446Z","iopub.status.idle":"2023-12-19T04:05:27.074145Z","shell.execute_reply.started":"2023-12-19T04:05:27.055424Z","shell.execute_reply":"2023-12-19T04:05:27.073250Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Label                                            Content  len  n_words  \\\n0      1  compensate career minimal interaction people l...  142       18   \n1      1  need talk understand autism convinced autistic...  177       26   \n2      1  legal limit low function avarage person high f...  220       32   \n3      1  autism know social situation make easy folk as...   96       15   \n4      1  need parenting advise regard risperidone greet...  296       43   \n\n   n_sent  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Content</th>\n      <th>len</th>\n      <th>n_words</th>\n      <th>n_sent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>compensate career minimal interaction people l...</td>\n      <td>142</td>\n      <td>18</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>need talk understand autism convinced autistic...</td>\n      <td>177</td>\n      <td>26</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>legal limit low function avarage person high f...</td>\n      <td>220</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>autism know social situation make easy folk as...</td>\n      <td>96</td>\n      <td>15</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>need parenting advise regard risperidone greet...</td>\n      <td>296</td>\n      <td>43</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_[\"Label\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T04:05:27.075396Z","iopub.execute_input":"2023-12-19T04:05:27.075699Z","iopub.status.idle":"2023-12-19T04:05:27.087694Z","shell.execute_reply.started":"2023-12-19T04:05:27.075673Z","shell.execute_reply":"2023-12-19T04:05:27.086694Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Label\n1    59631\n0    39368\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"train_, test = train_test_split(train_, test_size=0.2, random_state=42)\ntrain, val = train_test_split(train_, test_size=0.2, random_state=42)\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\ntrain_encodings = tokenizer(train['Content'].tolist(), max_length=128, truncation=True, padding=True, return_tensors='pt')\nval_encodings = tokenizer(val['Content'].tolist(), max_length=128, truncation=True, padding=True, return_tensors='pt')\ntest_encodings = tokenizer(test['Content'].tolist(), max_length=128, truncation=True, padding=True, return_tensors='pt')\n    \ntrain_labels = torch.tensor(train[\"Label\"].tolist())\nval_labels = torch.tensor(val[\"Label\"].tolist())","metadata":{"execution":{"iopub.status.busy":"2023-12-19T04:05:27.088889Z","iopub.execute_input":"2023-12-19T04:05:27.089210Z","iopub.status.idle":"2023-12-19T04:11:29.043789Z","shell.execute_reply.started":"2023-12-19T04:05:27.089184Z","shell.execute_reply":"2023-12-19T04:11:29.042800Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"388e0c083c0e4627b588a0fef7640868"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"014f6c137adb4aeba88bf20856727e7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9743d3b76e06457bb01d2514b6c6c88f"}},"metadata":{}}]},{"cell_type":"code","source":"class Mymodel(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=256)\n        self.head = torch.nn.Sequential(torch.nn.Linear(256,256),\n                                        torch.nn.ReLU(),\n                                        torch.nn.Linear(256,2),\n                                       )\n    def forward(self,x):\n        bert_emb = self.bert(input_ids=x[\"input_ids\"],\n                             attention_mask=x[\"attention_mask\"],\n                            ).logits\n        output = self.head(bert_emb)\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-12-19T04:11:29.045366Z","iopub.execute_input":"2023-12-19T04:11:29.046171Z","iopub.status.idle":"2023-12-19T04:11:29.052659Z","shell.execute_reply.started":"2023-12-19T04:11:29.046138Z","shell.execute_reply":"2023-12-19T04:11:29.051668Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = Mymodel()\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\ntrain_dataset = torch.utils.data.TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\nval_dataset = torch.utils.data.TensorDataset(val_encodings['input_ids'], val_encodings['attention_mask'], val_labels)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\ntest_dataset = torch.utils.data.TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'])\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\noptimizer = AdamW(model.parameters(), lr=1e-5,weight_decay=5e-5)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T04:11:29.053846Z","iopub.execute_input":"2023-12-19T04:11:29.054173Z","iopub.status.idle":"2023-12-19T04:11:37.642343Z","shell.execute_reply.started":"2023-12-19T04:11:29.054147Z","shell.execute_reply":"2023-12-19T04:11:37.641493Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cab0fa8ac8244d7b92f6a341107de7fa"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"criterium = torch.nn.CrossEntropyLoss()\n\ndef train_one_ep(model,dataloader):\n    total_loss = 0\n    total = 0\n    model.train()\n    for batch in train_loader:\n        inputs = {'input_ids': batch[0].to(device),\n                  'attention_mask': batch[1].to(device),\n                  'labels': batch[2].to(device)}\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterium(outputs,inputs['labels'].long())\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch[0].shape[0]\n        total += batch[0].shape[0]\n    return total_loss / total\n\ndef eval(model,dataloader):\n    model.eval()\n    total_loss = 0\n    total = 0\n    y_true, y_pred = [], []\n    for batch in val_loader:\n        inputs = {'input_ids': batch[0].to(device),\n                  'attention_mask': batch[1].to(device),\n                  'labels': batch[2].to(device)}\n        with torch.no_grad():\n            outputs = model(inputs)\n        loss = criterium(outputs,inputs['labels'].long())\n        total_loss += loss.item() * batch[0].shape[0]\n        total += batch[0].shape[0]\n        logits = outputs.detach().cpu().numpy()\n        predictions = logits[:,1]\n        y_true.extend(inputs['labels'].cpu().numpy())\n        y_pred.extend(predictions)\n    fpr, tpr, thresholds = roc_curve(np.array(y_true), np.array(y_pred))\n\n    return total_loss / total, auc(fpr, tpr)\n\ndef predict(model,dataloader):\n    model.eval()\n    y_pred = []\n    for batch in tqdm(test_loader):\n        inputs = {'input_ids': batch[0].to(device),\n                  'attention_mask': batch[1].to(device),\n                 }\n        with torch.no_grad():\n            outputs = model(inputs)\n        logits = outputs.softmax(dim=-1).detach().cpu().numpy()\n        predictions = logits[:,1]\n        y_pred.extend(predictions)\n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2023-12-19T04:11:37.645749Z","iopub.execute_input":"2023-12-19T04:11:37.646219Z","iopub.status.idle":"2023-12-19T04:11:37.660345Z","shell.execute_reply.started":"2023-12-19T04:11:37.646193Z","shell.execute_reply":"2023-12-19T04:11:37.659400Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"best_model = deepcopy(model)\nbest_auc = 0\nbest_iter = 0\npatience = 2\nnum_epochs = 5\n\nfor epoch in tqdm(range(num_epochs)):\n    train_loss = train_one_ep(model,train_loader)\n    val_loss,auc_roc = eval(model,val_loader)\n    print(\"Epoch {} : train_loss {:.3f} val_loss {:.3f} val_auc {:.3f}\".format(epoch,train_loss,val_loss,auc_roc))\n\n    if auc_roc > best_auc :\n        best_model = deepcopy(model)\n        best_auc = auc_roc\n        best_iter = epoch\n\n    if epoch - best_iter >= patience :\n        print(\"earlystop\")\n        break\n\nmodel = best_model","metadata":{"execution":{"iopub.status.busy":"2023-12-19T04:11:37.661603Z","iopub.execute_input":"2023-12-19T04:11:37.662577Z","iopub.status.idle":"2023-12-19T05:47:36.957319Z","shell.execute_reply.started":"2023-12-19T04:11:37.662544Z","shell.execute_reply":"2023-12-19T05:47:36.956389Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":" 20%|██        | 1/5 [23:54<1:35:37, 1434.34s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 0 : train_loss 0.508 val_loss 0.457 val_auc 0.858\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 2/5 [47:55<1:11:55, 1438.37s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 1 : train_loss 0.433 val_loss 0.443 val_auc 0.865\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 3/5 [1:11:55<47:58, 1439.31s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 2 : train_loss 0.386 val_loss 0.455 val_auc 0.865\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 3/5 [1:35:59<1:03:59, 1919.74s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 3 : train_loss 0.327 val_loss 0.479 val_auc 0.858\nearlystop\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"path = \"/kaggle/working/bert-base-uncased_model.pth\"\ntorch.save(model.state_dict(), path)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T05:47:36.958540Z","iopub.execute_input":"2023-12-19T05:47:36.958831Z","iopub.status.idle":"2023-12-19T05:47:37.682577Z","shell.execute_reply.started":"2023-12-19T05:47:36.958805Z","shell.execute_reply":"2023-12-19T05:47:37.681549Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"y_true, y_pred = [], []\nfor batch in val_loader:\n    inputs = {'input_ids': batch[0].to(device),\n              'attention_mask': batch[1].to(device),\n              'labels': batch[2].to(device)}\n    with torch.no_grad():\n        outputs = model(inputs)\n    logits = outputs.softmax(dim=-1).detach().cpu().numpy()\n    predictions = logits[:,1]\n    y_true.extend(inputs['labels'].cpu().numpy())\n    y_pred.extend(predictions)\n\nthresholds = np.linspace(0, 1, 100)\nf1_scores = []\nthreshold_values = []\n\nfor threshold in thresholds:\n    y_pred_thresholded = (y_pred >= threshold).astype(int)\n    f1 = f1_score(y_true, y_pred_thresholded)\n    f1_scores.append(f1)\n    threshold_values.append(threshold)\n\nf1_scores = np.array(f1_scores)\nthreshold_values = np.array(threshold_values)\n\nwindow_size = 5\nsmooth_f1_scores = np.convolve(f1_scores, np.ones(window_size)/window_size, mode='same')\n\noptimal_threshold = thresholds[np.argmax(smooth_f1_scores)]\nmax_f1_score = np.max(smooth_f1_scores)\n\nplt.figure(figsize=(10, 6))\nplt.plot(thresholds, f1_scores, label='F1 Score', color='blue')\nplt.plot(thresholds, smooth_f1_scores, label='F1 Score (smooth)', color='green')\nplt.scatter(optimal_threshold, max_f1_score, color='red', label='Optimal')\nplt.xlabel('Threshold')\nplt.ylabel('F1 Score')\nplt.legend()\nplt.grid(True)\nplt.show()\n\nprint(f\"Seuil Optimal: {optimal_threshold:.2f}\")\nprint(f\"Score F1 Maximum: {max_f1_score:.2f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\ntest_labels = test[\"Label\"]\ny_test_pred = predict(model,test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T05:49:33.742368Z","iopub.execute_input":"2023-12-19T05:49:33.742741Z","iopub.status.idle":"2023-12-19T05:51:56.359133Z","shell.execute_reply.started":"2023-12-19T05:49:33.742703Z","shell.execute_reply":"2023-12-19T05:51:56.358250Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|██████████| 619/619 [02:22<00:00,  4.34it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"y_test_pred = np.array(y_test_pred)\nthreshold = 0.38\ny_test_pred = (y_test_pred >= threshold).astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T05:53:16.597749Z","iopub.execute_input":"2023-12-19T05:53:16.598125Z","iopub.status.idle":"2023-12-19T05:53:16.603510Z","shell.execute_reply.started":"2023-12-19T05:53:16.598092Z","shell.execute_reply":"2023-12-19T05:53:16.602533Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Calculate accuracy\naccuracy = accuracy_score(test_labels, y_test_pred)\n\n# Calculate precision\nprecision = precision_score(test_labels, y_test_pred)\n\n# Calculate recall\nrecall = recall_score(test_labels, y_test_pred)\n\n# Calculate F1 score\nf1 = f1_score(test_labels, y_test_pred)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Precision: {precision}\")\nprint(f\"Recall: {recall}\")\nprint(f\"F1 Score: {f1}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Calculate the confusion matrix\ncm = confusion_matrix(test_labels, y_test_pred)\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n            xticklabels=[0, 1], yticklabels=[0, 1])\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = [\"the real reason why you be sad you be attach to people who have be distant with you you be pay attention to people who ignore you you make time for people who be too busy for you you be too care to people who be care less when it come to you let those people go\",\n        \"when your therapist be write down some of the things she be worry about barely eat yup depression and this eat disorder be go to kill me one day and i do not even care i just want to fuck die\"\n        \"my best friend be all the way across the country and she tell me if i kill myself she be not fly home to come to my service fuck me right what be best friends for anyway\",\n        \"all i want be to be happyhow be that so hard do people really have to put me down every single day i be just so do with everyone\",\n        \"i be go to be the quiet girl in school this year the one that sit in the back the one with no friends the one that hide her cut\"]\n\ndf = pd.DataFrame(test_data, columns=[\"Content\"])","metadata":{"execution":{"iopub.status.busy":"2023-12-19T06:14:36.770529Z","iopub.execute_input":"2023-12-19T06:14:36.771338Z","iopub.status.idle":"2023-12-19T06:14:36.776846Z","shell.execute_reply.started":"2023-12-19T06:14:36.771301Z","shell.execute_reply":"2023-12-19T06:14:36.775892Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"test_encodings = tokenizer(df[\"Content\"].tolist(), truncation=True, padding=True, return_tensors='pt')\n\ntest_dataset = torch.utils.data.TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'])\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T06:15:10.226340Z","iopub.execute_input":"2023-12-19T06:15:10.227068Z","iopub.status.idle":"2023-12-19T06:15:10.239224Z","shell.execute_reply.started":"2023-12-19T06:15:10.227036Z","shell.execute_reply":"2023-12-19T06:15:10.238271Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df[\"Score\"] = predict(model,test_loader)\ndf[\"Result\"] = (df[\"Score\"] > 0.5).astype(float)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T06:15:12.505359Z","iopub.execute_input":"2023-12-19T06:15:12.506067Z","iopub.status.idle":"2023-12-19T06:15:12.552989Z","shell.execute_reply.started":"2023-12-19T06:15:12.506031Z","shell.execute_reply":"2023-12-19T06:15:12.552069Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 28.96it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(df)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T06:15:23.288881Z","iopub.execute_input":"2023-12-19T06:15:23.289286Z","iopub.status.idle":"2023-12-19T06:15:23.297773Z","shell.execute_reply.started":"2023-12-19T06:15:23.289251Z","shell.execute_reply":"2023-12-19T06:15:23.296689Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"                                             Content     Score  Result\n0  the real reason why you be sad you be attach t...  0.849609     1.0\n1  when your therapist be write down some of the ...  0.743840     1.0\n2  all i want be to be happyhow be that so hard d...  0.931299     1.0\n3  i be go to be the quiet girl in school this ye...  0.894988     1.0\n","output_type":"stream"}]}]}